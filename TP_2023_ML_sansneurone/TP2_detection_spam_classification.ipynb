{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45syPB7NruD-"
      },
      "source": [
        "# Introduction à l'apprentissage automatique: Classification\n",
        "\n",
        "<br>\n",
        "\n",
        "### Détection de spam\n",
        "\n",
        "<br>\n",
        "\n",
        "Dans ce TP, nous allons entraîner des classifieurs pour décider si un mail est un spam ou non.\n",
        "\n",
        "<br>\n",
        "\n",
        "Tout d'abord, quelques indications sur l'utilisation des méthodes d'apprentissage de ̀`scikit-learn`.\n",
        "\n",
        "Les méthodes d'apprentissage supervisé de `scikit-learn` permettent de définir un objet, doté de différents attributs et méthodes, dont `cross_val_score` (pour calculer un score de validation croisée), `fit` (pour procéder à l'apprentissage), `predict` (pour prédire les classes des éléments d'une base de test), ou `score` pour calculer la proportion d'observations bien classées dans la base de test, sur laquelle on peut comparer la classe prédite à la \"vraie\" classe.\n",
        "\n",
        "Ci-dessous, un exemple d'utilisation de la classification au plus proche voisin, dans un scénario où on suppose disposer d'une base d'apprentissage $(X_{train},y_{train})$, et d'une base de test $X_{test}$ pour laquelle on connaît $y_{test}$, de manière à valider l'apprentissage sur la base de test. Si on veut changer de classifieur, il suffit d'utiliser un autre constructeur que `neighbors.KNeighborsClassifier` et de passer les paramètres adéquats.\n",
        "\n",
        "```python\n",
        "# (le code suivant ne peut pas être exécuté \"tel quel\"...)\n",
        "\n",
        "# classifieur au plus proche voisin (on peut changer le paramètre n_neighbors):\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=1)  \n",
        "\n",
        "# calcul d'un score moyen de validation croisée \"à 5 plis\" sur (X_train,y_train)\n",
        "scores = cross_val_score(knn,X_train,y_train,cv=5)\n",
        "print(\"score moyen de validation croisée: %0.3f (+/- %0.3f)\" % (scores.mean(),2*scores.std()))\n",
        "\n",
        "# la prédiction d'une nouvelle observation consistera à chercher le p.p.v. dans X_train,\n",
        "# et à associer la classe de ce p.p.v., donnée par y_train:\n",
        "knn.fit(X_train,y_train)  \n",
        "# Remarque: il n'y a pas d'apprentissage à proprement parler pour les p.p.v.,\n",
        "# il s'agit juste de préciser la base dans laquelle seront cherchés les plus proches voisins\n",
        "\n",
        "# on stocke dans y_pred les classes prédites sur un ensemble de test X_test:\n",
        "y_pred = knn.predict(X_test)  \n",
        "\n",
        "# calcul d'un score lorsqu'on connaît les vraies classes des observations de X_test:\n",
        "# (proportion d'observations pour lesquelles y_test==y_pred)\n",
        "score = knn.score(X_test,y_test)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK3wQBJfruEA"
      },
      "source": [
        "## Préliminaires\n",
        "\n",
        "<br>\n",
        "\n",
        "Commençons par charger les bibliothèques utiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLcEzU5TruEA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn import neighbors, linear_model, naive_bayes, metrics\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftIlYG8QruEB"
      },
      "source": [
        "Ensuite, on charge les données: récupérez au préalable le fichier `spambase.data` disponible sur le [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/94/spambase) (Cliquez sur \"Download\" pour télécharger les fichiers). La description complète de la base est dans le fichier `spambase.name`, à ouvrir avec un éditeur de texte.\n",
        "\n",
        "<br>\n",
        "\n",
        "La cellule suivante charge les données. On forme une base d'entraînement avec 80% des données (choix aléatoire), et on garde 20% des données pour faire une base de test. Dans la cellule suivante, on fixe la graîne du générateur aléatoire (`random_state=42`, la valeur est arbitraire) de manière à ce que l'on ait tous les mêmes résultats afin de faciliter la comparaison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCcEmxnYruEC",
        "outputId": "1bfe3016-4941-4d5d-92f2-5fa279addc25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.000e+00 6.400e-01 6.400e-01 ... 6.100e+01 2.780e+02 1.000e+00]\n",
            " [2.100e-01 2.800e-01 5.000e-01 ... 1.010e+02 1.028e+03 1.000e+00]\n",
            " [6.000e-02 0.000e+00 7.100e-01 ... 4.850e+02 2.259e+03 1.000e+00]\n",
            " ...\n",
            " [3.000e-01 0.000e+00 3.000e-01 ... 6.000e+00 1.180e+02 0.000e+00]\n",
            " [9.600e-01 0.000e+00 0.000e+00 ... 5.000e+00 7.800e+01 0.000e+00]\n",
            " [0.000e+00 0.000e+00 6.500e-01 ... 5.000e+00 4.000e+01 0.000e+00]]\n",
            "(4601, 58)\n",
            "(3680, 57)\n",
            "(3680,)\n",
            "(921, 57)\n",
            "(921,)\n",
            "[[9.000e-02 0.000e+00 9.000e-02 ... 6.813e+00 4.940e+02 1.458e+03]\n",
            " [0.000e+00 0.000e+00 0.000e+00 ... 1.800e+00 8.000e+00 4.500e+01]\n",
            " [0.000e+00 0.000e+00 2.430e+00 ... 2.319e+00 1.200e+01 1.670e+02]\n",
            " ...\n",
            " [0.000e+00 0.000e+00 0.000e+00 ... 2.333e+00 1.000e+01 4.900e+01]\n",
            " [0.000e+00 2.300e-01 0.000e+00 ... 1.616e+00 1.300e+01 1.730e+02]\n",
            " [1.000e-01 0.000e+00 4.100e-01 ... 1.915e+00 2.900e+01 3.390e+02]]\n",
            "[1. 0. 0. ... 0. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "data = np.loadtxt('spambase.data', delimiter=',')\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[:,:-1], data[:,-1], test_size=0.2, random_state=42)\n",
        "# pour vérifier que les données sont bien chargées:\n",
        "print(data)\n",
        "print(data.shape)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(X_train)\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtaSO0JeruEC"
      },
      "source": [
        "__Question 1__. A partir de la description de la base de données, justifiez la manière employée pour charger les données en `X` (observations) et `y` (labels). Quelles sont les caractéristiques des observations, les labels, et quel est le rapport avec le problème initial?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kejO8F7hruED"
      },
      "source": [
        "<font color=red>\n",
        "Votre réponse: <br>\n",
        "Cette base de données contient des caractéristiques extraites d'e-mails, notamment la fréquence d'apparition de certains mots, de certains caractères, ainsi que des informations sur l'utilisation des majuscules.<br><br>\n",
        "L'objectif du problème initial est de classer les e-mails en tant que spam ou non-spam en fonction de ces caractéristiques extraites. Par conséquent, les observations (X) correspondent aux caractéristiques extraites des e-mails, et les labels (y) correspondent à la classification en spam (1) ou non-spam (0), c'est de la  classification binaire. <br>\n",
        "Il y a 48 attributs continus de word_freq_WORD, les 6 attributs continus de char_freq_CHAR, ainsi que les trois attributs continus de capital_run_length_average, capital_run_length_longest, et capital_run_length_total comme variables explicatives (X), et l'attribut nominal spam comme la variable cible (y).\n",
        "    \n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNlBf3sNruED"
      },
      "source": [
        "## Classification aux plus proches voisins\n",
        "\n",
        "<br>\n",
        "\n",
        "Mettez en oeuvre les classifications au plus proche voisin et aux 5 plus proches voisins. Vous calculerez le score moyen de validation croisée à 5 plis sur la base d'apprentissage ainsi que le score obtenu sur la base de test. Vous vous inspirerez du code détaillé en introduction.\n",
        "\n",
        "__Question 2__. Quelle est la métrique utilisée pour déterminer les plus proches voisins? Quel est ce \"score\" calculé exactement? Quel lien entre score de validation croisée et score sur la base de test?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U3qf8I9ruED",
        "outputId": "a970f610-c3b0-4dc3-9ec8-6e6c88289b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score moyen de validation croisée: 0.803 (+/- 0.016)\n",
            "score moyen de test : 0.808 (+/- 0.000)\n"
          ]
        }
      ],
      "source": [
        "# votre code ici pour 1-ppv:\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "# calcul d'un score moyen de validation croisée \"à 5 plis\" sur (X_train,y_train)\n",
        "scores = cross_val_score(knn,X_train,y_train,cv=5)\n",
        "print(\"score moyen de validation croisée: %0.3f (+/- %0.3f)\" % (scores.mean(),2*scores.std()))\n",
        "\n",
        "# la prédiction d'une nouvelle observation consistera à chercher le p.p.v. dans X_train,\n",
        "# et à associer la classe de ce p.p.v., donnée par y_train:\n",
        "knn.fit(X_train,y_train)\n",
        "# Remarque: il n'y a pas d'apprentissage à proprement parler pour les p.p.v.,\n",
        "# il s'agit juste de préciser la base dans laquelle seront cherchés les plus proches voisins\n",
        "\n",
        "# on stocke dans y_pred les classes prédites sur un ensemble de test X_test:\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# calcul d'un score lorsqu'on connaît les vraies classes des observations de X_test:\n",
        "# (proportion d'observations pour lesquelles y_test==y_pred)\n",
        "score = knn.score(X_test,y_test)\n",
        "print(\"score moyen de test : %0.3f (+/- %0.3f)\" % (score.mean(),2*score.std()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NysGdLKXruEE",
        "outputId": "ee391991-f033-44b2-b074-77027a5df0e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "y_pred[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL5gK6hFruEE",
        "outputId": "8622677b-38e5-435f-8b06-0807e8505a52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "y_test[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxXNDK69ruEE",
        "outputId": "22a179c4-43bf-47b7-a879-ff908591fb76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score moyen de validation croisée: 0.791 (+/- 0.023)\n",
            "score moyen de test : 0.790 (+/- 0.000)\n"
          ]
        }
      ],
      "source": [
        "# votre code ici pour 5-ppv:\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# calcul d'un score moyen de validation croisée \"à 5 plis\" sur (X_train,y_train)\n",
        "scores = cross_val_score(knn,X_train,y_train,cv=5)\n",
        "print(\"score moyen de validation croisée: %0.3f (+/- %0.3f)\" % (scores.mean(),2*scores.std()))\n",
        "\n",
        "# la prédiction d'une nouvelle observation consistera à chercher le p.p.v. dans X_train,\n",
        "# et à associer la classe de ce p.p.v., donnée par y_train:\n",
        "knn.fit(X_train,y_train)\n",
        "# Remarque: il n'y a pas d'apprentissage à proprement parler pour les p.p.v.,\n",
        "# il s'agit juste de préciser la base dans laquelle seront cherchés les plus proches voisins\n",
        "\n",
        "# on stocke dans y_pred les classes prédites sur un ensemble de test X_test:\n",
        "y_pred_kn1 = knn.predict(X_test)\n",
        "\n",
        "# calcul d'un score lorsqu'on connaît les vraies classes des observations de X_test:\n",
        "# (proportion d'observations pour lesquelles y_test==y_pred)\n",
        "score = knn.score(X_test,y_test)\n",
        "print(\"score moyen de test : %0.3f (+/- %0.3f)\" % (score.mean(),2*score.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvPpK27NruEF"
      },
      "source": [
        "<font color=red>\n",
        "Votre réponse:<br>\n",
        "La métrique utilisée pour déterminer les plus proches voisins est la distance euclidienn (métrique par défaut pour le classificateur k des plus proches voisins (k-NN) de scikit-learn). La distance euclidienne mesure la distance spatiale entre deux points.<br>\n",
        "Le \"score\" calculé exactement dans le code est la proportion d'observations correctement classées des y_test, c'est la précision de la classification des valeurs.<br>\n",
        "Le score de validation croisée est calculé en utilisant une validation croisée à 5 plis sur la base d'apprentissage. Il divise la base d'apprentissage en 5 sous-ensembles (plis), utilise 4 d'entre eux pour l'apprentissage et le dernier pour la validation. Celui-ci utilise les x_train seulement. Alors qu'à contrario, le score sur la base de test est calculé en utilisant le modèle entraîné sur la base d'apprentissage pour prédire les classes de la base de test.<br>\n",
        "Ici les scores sont similaires ce qui peut suggérer que le modèle d'entrainement est plutot bon.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rht7fvwcruEF"
      },
      "source": [
        "__Question 4__. Pré-traitez les données par standardisation, comme expliqué ici sur [la documentation scikit-learn](https://scikit-learn.org/stable/modules/preprocessing.html) (utilisez le `StandardScaler` comme indiqué dans la 3ème cellule, de manière à utiliser la même normalisation sur la base d'apprentissage et sur la base de test, c'est important), puis recalculez les scores des deux classifieurs précédents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c3vv3VIruEF",
        "outputId": "ed965932-ee4d-4ec3-ae1b-24e7bfd10b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score moyen de validation croisée: 0.906 (+/- 0.013)\n",
            "score moyen de test : 0.894 (+/- 0.000)\n"
          ]
        }
      ],
      "source": [
        "# votre code:\n",
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "\n",
        "X_scaled = scaler.transform(X_train)\n",
        "X_scaled_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# calcul d'un score moyen de validation croisée \"à 5 plis\" sur (X_train,y_train)\n",
        "scores = cross_val_score(knn,X_scaled,y_train,cv=5)\n",
        "print(\"score moyen de validation croisée: %0.3f (+/- %0.3f)\" % (scores.mean(),2*scores.std()))\n",
        "\n",
        "# la prédiction d'une nouvelle observation consistera à chercher le p.p.v. dans X_train,\n",
        "# et à associer la classe de ce p.p.v., donnée par y_train:\n",
        "knn.fit(X_scaled,y_train)\n",
        "# Remarque: il n'y a pas d'apprentissage à proprement parler pour les p.p.v.,\n",
        "# il s'agit juste de préciser la base dans laquelle seront cherchés les plus proches voisins\n",
        "\n",
        "# on stocke dans y_pred les classes prédites sur un ensemble de test X_test:\n",
        "y_pred_kn5 = knn.predict(X_scaled_test)\n",
        "\n",
        "# calcul d'un score lorsqu'on connaît les vraies classes des observations de X_test:\n",
        "# (proportion d'observations pour lesquelles y_test==y_pred)\n",
        "score = knn.score(X_scaled_test,y_test)\n",
        "print(\"score moyen de test : %0.3f (+/- %0.3f)\" % (score.mean(),2*score.std()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5tP0rp-ruEF",
        "outputId": "2e78d1c8-09a7-4acf-f4f7-f57ee55efd40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[9.000e-02, 0.000e+00, 9.000e-02, 0.000e+00, 3.900e-01, 9.000e-02,\n",
              "        9.000e-02, 0.000e+00, 1.900e-01, 2.900e-01, 3.900e-01, 4.800e-01,\n",
              "        0.000e+00, 5.800e-01, 0.000e+00, 8.700e-01, 1.900e-01, 0.000e+00,\n",
              "        1.660e+00, 4.100e+00, 1.660e+00, 0.000e+00, 3.900e-01, 1.900e-01,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 1.390e-01, 0.000e+00, 3.100e-01, 1.550e-01, 0.000e+00,\n",
              "        6.813e+00, 4.940e+02, 1.458e+03],\n",
              "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.580e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        7.900e-01, 0.000e+00, 7.900e-01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        7.900e-01, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        1.240e-01, 1.240e-01, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        1.800e+00, 8.000e+00, 4.500e+01]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[:2,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7Smy0lgruEF",
        "outputId": "5d5e2a90-bca9-40a5-a1e6-46b15747b828"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-3.84417967e-02, -1.62823436e-01, -3.73283587e-01,\n",
              "        -4.43387016e-02,  1.25329068e-01, -1.75557108e-02,\n",
              "        -4.94618697e-02, -2.58223628e-01,  3.74143676e-01,\n",
              "         7.84018383e-02,  1.64169725e+00, -7.44333103e-02,\n",
              "        -3.27398098e-01,  1.51199468e+00, -1.90055678e-01,\n",
              "         7.05973261e-01,  1.15944336e-01, -3.45099898e-01,\n",
              "         6.08468580e-03,  7.83188746e+00,  7.10708263e-01,\n",
              "        -1.16300745e-01,  8.23756701e-01,  2.01038747e-01,\n",
              "        -3.26710260e-01, -3.00878899e-01, -2.30922222e-01,\n",
              "        -2.31071959e-01, -1.72682655e-01, -2.24879107e-01,\n",
              "        -1.74395864e-01, -1.43223289e-01, -1.73866411e-01,\n",
              "        -1.45765474e-01, -1.93393004e-01, -2.42335411e-01,\n",
              "        -3.30036623e-01, -5.64810168e-02, -1.78189932e-01,\n",
              "        -1.86445138e-01, -1.21635838e-01, -1.74633824e-01,\n",
              "        -2.03750279e-01, -1.27828730e-01, -2.99465798e-01,\n",
              "        -2.11088191e-01, -7.04194454e-02, -1.17147007e-01,\n",
              "        -1.57562225e-01, -8.70397336e-03, -1.73306666e-01,\n",
              "         5.29806142e-02,  3.21641987e-01, -1.22745187e-01,\n",
              "         5.10246830e-02,  2.10678454e+00,  2.08342875e+00],\n",
              "       [-3.41222369e-01, -1.62823436e-01, -5.50609354e-01,\n",
              "        -4.43387016e-02, -4.52759566e-01, -3.44393902e-01,\n",
              "        -2.97595333e-01, -2.58223628e-01, -3.19924558e-01,\n",
              "        -3.75563990e-01, -2.95841929e-01,  1.17959774e+00,\n",
              "        -3.27398098e-01, -1.76781934e-01, -1.90055678e-01,\n",
              "        -2.92764750e-01, -3.19508636e-01, -3.45099898e-01,\n",
              "        -4.84613805e-01, -1.57775726e-01, -8.31630426e-03,\n",
              "        -1.16300745e-01, -2.87897743e-01, -2.04168205e-01,\n",
              "        -3.26710260e-01, -3.00878899e-01, -2.30922222e-01,\n",
              "        -2.31071959e-01, -1.72682655e-01, -2.24879107e-01,\n",
              "        -1.74395864e-01, -1.43223289e-01, -1.73866411e-01,\n",
              "        -1.45765474e-01, -1.93393004e-01, -2.42335411e-01,\n",
              "        -3.30036623e-01, -5.64810168e-02, -1.78189932e-01,\n",
              "        -1.86445138e-01, -1.21635838e-01, -1.74633824e-01,\n",
              "         3.23710254e+00, -1.27828730e-01, -2.99465798e-01,\n",
              "        -2.11088191e-01, -7.04194454e-02, -1.17147007e-01,\n",
              "         3.45899003e-01, -6.11845118e-02, -1.73306666e-01,\n",
              "        -3.09886797e-01, -3.05752538e-01, -1.22745187e-01,\n",
              "        -1.02592159e-01, -2.13686862e-01, -4.13384669e-01]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_scaled[:2,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJWi7Dn9ruEG"
      },
      "source": [
        "<font color=red>\n",
        "    Votre réponse:<br>\n",
        "    \n",
        "Dans ce code, nous effectuons le prétraitement des données en utilisant la standardisation à l'aide de StandardScaler de scikit-learn. Ensuite, nous recalculons les scores des classifieurs k-NN (k plus proches voisins) sur la base d'apprentissage et de test après ce prétraitement.<br><br>\n",
        "La standardisation des données signifie que nous centrons les données autour de zéro (moyenne de 0) et les mettons à l'échelle pour avoir une variance de 1.<br><br>\n",
        "Le score moyen de validation croisée est élevé (environ 0.906), ce qui indique que le modèle k-NN fonctionne bien sur la base d'apprentissage après la standardisation des données.\n",
        "Le score moyen de test est également élevé (environ 0.894), ce qui suggère que le modèle généralise bien sur de nouvelles données (base de test).<br>\n",
        "Pour rappel les scores sans pré-traitement des données était nettement plus faible : <br><br>\n",
        "score moyen de validation croisée: 0.791 (+/- 0.023)\n",
        "score moyen de test : 0.790 (+/- 0.000)\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqefrJYXruEG"
      },
      "source": [
        "## Classifieur naïf de Bayes gaussien et régression logistique\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "__Question 5__. Pourquoi le classifieur naïf de Bayes gaussien ne nécessite-t-il pas de standardisation préalable des données ? (vous pouvez vérifier que la normalisation joue tout de même un faible rôle: elle a sans doute une influence sur le comportement de l'algorithme d'estimation des paramètres).\n",
        "\n",
        "\n",
        "Mettez en oeuvre le classifieur naïf de Bayes gaussien (lisez le début de la [documentation](https://scikit-learn.org/stable/modules/naive_bayes.html) où vous retrouverez le contenu du cours, puis la syntaxe de `GaussianNB` [ici](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)), ainsi que le classifieur de la régression logistique ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)).\n",
        "\n",
        "Pour ce dernier classifieur, passez l'option `max_iter=2000` si vous avez un avertissement concernant la convergence de l'optimisation, de la manière suivante:\n",
        "`LR = linear_model.LogisticRegression(max_iter=2000)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONFOpHswruEG",
        "outputId": "567793a7-8a4c-4144-869d-7a70d9839ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.2 ms, sys: 11 µs, total: 2.21 ms\n",
            "Wall time: 17.8 ms\n",
            "naive score: 0.820847\n"
          ]
        }
      ],
      "source": [
        "# votre code pour le classifieur naïf de Bayes gaussien (sur les données originales):\n",
        "from sklearn import naive_bayes\n",
        "\n",
        "# votre code pour le classifieur naif Gaussien:\n",
        "naive = naive_bayes.GaussianNB()\n",
        "naive.fit(X_train, y_train)\n",
        "%time y_pred_naive = naive.predict(X_test)\n",
        "print('naive score: %f' % metrics.accuracy_score(y_test, y_pred_naive))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRmhrhXRruEG",
        "outputId": "ec3ecdf0-58e8-4526-ebb9-86de206586a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 364 µs, sys: 789 µs, total: 1.15 ms\n",
            "Wall time: 627 µs\n",
            "linear score: 0.921824\n"
          ]
        }
      ],
      "source": [
        "# votre code pour la régression logistique (sur les données standardisées):\n",
        "from sklearn import linear_model\n",
        "\n",
        "linear = linear_model.LogisticRegression(max_iter=2000)\n",
        "linear.fit(X_train, y_train)\n",
        "%time y_pred_linear = linear.predict(X_test)\n",
        "print('linear score: %f' % metrics.accuracy_score(y_test, y_pred_linear))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzzoktQxruEG"
      },
      "source": [
        "<font color=red>\n",
        "Votre réponse:<br>\n",
        "Dans la classification par naive gaussienne, la formule qui nous permet de calculer \"y\" comporte déjà un pré traitement des données car on fait (les valeurs d'entrées - la moyenne des y)² / l'écart type au carré.<br><br>\n",
        "Ceci permet de pré-traiter les données.\n",
        "\n",
        "    \n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1RPC94uruEH"
      },
      "source": [
        "## Analyse des résultats\n",
        "\n",
        "<br>\n",
        "\n",
        "On dispose des matrices de confusion, décrites [ici](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html), et des rapports de classification, décrits [là](https://scikit-learn.orgz/stable/modules/generated/sklearn.metrics.classification_report.html).\n",
        "\n",
        "__Question 6__. Affichez ces matrices et rapports pour les quatre classifieurs testés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNzF6f68ruEH",
        "outputId": "0daa25cd-8e89-45d5-e6b4-cc51038d8919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matrice linear : \n",
            " [[505  26]\n",
            " [ 46 344]] \n",
            "matrice naive \n",
            " [[387 144]\n",
            " [ 21 369]] \n",
            "matrice kn1 \n",
            " [[450  81]\n",
            " [112 278]] \n",
            "matrice kn5 \n",
            " [[494  37]\n",
            " [ 61 329]]\n",
            "\n",
            "classification linear : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.95      0.93       531\n",
            "         1.0       0.93      0.88      0.91       390\n",
            "\n",
            "    accuracy                           0.92       921\n",
            "   macro avg       0.92      0.92      0.92       921\n",
            "weighted avg       0.92      0.92      0.92       921\n",
            " \n",
            "classification naive \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.73      0.82       531\n",
            "         1.0       0.72      0.95      0.82       390\n",
            "\n",
            "    accuracy                           0.82       921\n",
            "   macro avg       0.83      0.84      0.82       921\n",
            "weighted avg       0.85      0.82      0.82       921\n",
            " \n",
            "classification kn1 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.85      0.82       531\n",
            "         1.0       0.77      0.71      0.74       390\n",
            "\n",
            "    accuracy                           0.79       921\n",
            "   macro avg       0.79      0.78      0.78       921\n",
            "weighted avg       0.79      0.79      0.79       921\n",
            " \n",
            "classification kn2 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.93      0.91       531\n",
            "         1.0       0.90      0.84      0.87       390\n",
            "\n",
            "    accuracy                           0.89       921\n",
            "   macro avg       0.89      0.89      0.89       921\n",
            "weighted avg       0.89      0.89      0.89       921\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# votre code ici:\n",
        "\n",
        "#librairie\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "#matrice de confusion\n",
        "matrice_linear = confusion_matrix(y_test, y_pred_linear)\n",
        "matrice_naive = confusion_matrix(y_test, y_pred_naive)\n",
        "matrice_kn1 = confusion_matrix(y_test, y_pred_kn1)\n",
        "matrice_kn5 = confusion_matrix(y_test, y_pred_kn5)\n",
        "print(\"matrice linear : \\n\", matrice_linear,\"\\nmatrice naive \\n\",matrice_naive ,\"\\nmatrice kn1 \\n\", matrice_kn1,\"\\nmatrice kn5 \\n\",matrice_kn5)\n",
        "\n",
        "#rapports de classifications\n",
        "class_linear = classification_report(y_test, y_pred_linear)\n",
        "class_naive = classification_report(y_test, y_pred_naive)\n",
        "class_kn1 = classification_report(y_test, y_pred_kn1)\n",
        "class_kn5 = classification_report(y_test, y_pred_kn5)\n",
        "print(\"\\nclassification linear : \\n\", class_linear,\"\\nclassification naive \\n\",class_naive ,\"\\nclassification kn1 \\n\", class_kn1,\"\\nclassification kn2 \\n\",class_kn5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQisQqu8ruEH"
      },
      "source": [
        "__Question 7__. Ici, par quoi pourraient s'expliquer les performances modestes du classifieur naïf de Bayes ?\n",
        "A ce stade, quel classifieur préfére-t-on et pourquoi? Dans une application de détection de spams, cherche-t-on réellement à minimiser le taux d'erreur global?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GFcVpMqruEH"
      },
      "source": [
        "<font color=red>\n",
        "Réponse: <br>\n",
        "Le classifieur le plus performant est sans aucun doute la régression logistique, on peut l'identifier grâce à son nombre élever de vrai positif et vrai négatif, son nombre faible de faux négatif et faux positif, mais aussi grâce à ses scores dans le rapport de classifications.\n",
        "<BR>\n",
        "Mais le classifieur naive est intéressant car il y a moins de faux positif, donc moins de mails non spam qui iront dans les spams.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKVhNbRKruEH"
      },
      "source": [
        "Le classifieur bayésien naïf gaussien et le classifieur de la régression logistique s'appuient tous deux sur la règle du maximum a posteriori. Ils permettent d'estimer la probabilité a posteriori $p(C_1|x)$ et détectent un spam lorsque $p(C_1|x)>1/2$, où $C_1$ désigne la classe \"spam\" et $x$ est une observation. Les deux classifieurs mettent en oeuvre le classifieur de Bayes, qui minimise le risque moyen de prédiction (le taux d'erreur).  Le taux d'erreur \"compte\" de la même manière les erreurs sur les deux classes.\n",
        "\n",
        "Si on préfère réduire le taux de faux positif de la méthode (proportion de mails détectés à tort comme \"spam\"), on peut relever le seuil de probabilité.\n",
        "\n",
        "Les classifieurs `LogisticRegression` et `GaussianNB` possèdent tous deux une méthode `predict_proba` qui, pour un tableau d'observations, fournit la probabilité a posteriori de chaque classe, comme l'affiche la cellule suivante. On remarque que pour chaque observation $x$, $p(C_0|x)+p(C_1|x)=1$.  (attention, la documentation n'est pas très claire, `predict_proba` fournit bien la probabilité a posteriori, et pas la vraisemblance $p(x|C_k)$)\n",
        "\n",
        "Remarquons qu'aucune probabilité n'est fournie par la classification aux plus proches voisins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1Yl453GruEH",
        "outputId": "6e3e9db2-9c17-4fc0-a64c-8b530694875d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probabilités a posteriori pour GNB:\n",
            "[[5.19907033e-13 1.00000000e+00]\n",
            " [1.00000000e+00 3.06819165e-10]\n",
            " [1.00000000e+00 6.84756259e-16]\n",
            " ...\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [9.99218390e-01 7.81609538e-04]\n",
            " [1.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "probabilités a posteriori pour LR:\n",
            "[[1.60047981e-06 9.99998400e-01]\n",
            " [9.94232826e-01 5.76717356e-03]\n",
            " [9.34978227e-01 6.50217731e-02]\n",
            " ...\n",
            " [9.99976336e-01 2.36644591e-05]\n",
            " [9.75137668e-01 2.48623318e-02]\n",
            " [3.39631313e-03 9.96603687e-01]]\n"
          ]
        }
      ],
      "source": [
        "print(\"probabilités a posteriori pour naive:\")\n",
        "print(naive.predict_proba(X_test))\n",
        "print(\"\\nprobabilités a posteriori pour linear:\")\n",
        "print(linear.predict_proba(X_scaled_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSYQAP9bruEH",
        "outputId": "2f8f33db-5781-4c32-d05d-c29a20be82a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Régression logistique à seuil:\n",
            "score sur la base de test: 0.883822\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.97      0.91       531\n",
            "         1.0       0.95      0.77      0.85       390\n",
            "\n",
            "    accuracy                           0.88       921\n",
            "   macro avg       0.90      0.87      0.88       921\n",
            "weighted avg       0.89      0.88      0.88       921\n",
            "\n",
            "matrice de confusion:\n",
            "[[514  17]\n",
            " [ 90 300]]\n"
          ]
        }
      ],
      "source": [
        "p=0.85  # constatez que p=0.5 fournit les mêmes résultats pour y_pred_lr et y_pred_LRb\n",
        "y_pred_linear = (linear.predict_proba(X_scaled_test)[:,1] >= p).astype(int)\n",
        "#print(y_pred_LRb)   # pour visualiser les classes prédites\n",
        "#print(y_pred_lr)\n",
        "score_linear = 1-np.mean(np.abs(y_test-y_pred_linear))  # calcul du taux de reconnaissance\n",
        "\n",
        "print(\"\\nRégression logistique à seuil:\")\n",
        "print('score sur la base de test: %2f' %score_linear)\n",
        "print(metrics.classification_report(y_test,y_pred_linear))\n",
        "print(\"matrice de confusion:\")\n",
        "print(metrics.confusion_matrix(y_test,y_pred_linear))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC3Hy9K7ruEI"
      },
      "source": [
        "__Question 8__. Quelle valeur du seuil de probabilité $p$ faut-il choisir pour assurer un rappel de la classe \"non spam\" d'au moins 0.98?\n",
        "Que penser de cet algorithme de détection de spam?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGONWFRIruEI"
      },
      "source": [
        "<font color=red>\n",
        "    \n",
        "Réponse:\n",
        "    \n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nkkbq-QdruEI"
      },
      "outputs": [],
      "source": [
        "p = 0.85"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}